# Todo Application - Technical Planning Document

**Project**: Evolution of Todo
**Planning Method**: Spec-Driven Development
**Based On**: SPECIFICATION.md, CONSTITUTION.md, /specs/technical/*
**Last Updated**: 2025-12-25

---

## EXECUTIVE SUMMARY

This technical plan outlines the implementation strategy for all 5 phases of the Evolution of Todo project. Each phase builds upon the previous, following strict Spec-Driven Development principles where specifications are refined until Claude Code generates correct implementations.

**Development Approach**: Research â†’ Foundation â†’ Analysis â†’ Synthesis

**Key Constraints**:
- All code generated by Claude Code (no manual coding)
- Specifications written before implementation
- Constitution principles enforced throughout
- Each phase fully functional before proceeding to next

---

## ARCHITECTURE OVERVIEW

### System Evolution Across Phases

```
PHASE I: Console Application
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python Console Interface           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Menu System                â”‚   â”‚
â”‚  â”‚  - Add/View/Update/Delete   â”‚   â”‚
â”‚  â”‚  - Mark Complete            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚                       â”‚
â”‚             â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  In-Memory Data Store       â”‚   â”‚
â”‚  â”‚  tasks: Dict[int, Task]     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE II: Full-Stack Web Application
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js 16     â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI        â”‚â”€â”€â”€â”€â–¶â”‚  Neon DB     â”‚
â”‚   Frontend       â”‚     â”‚   Backend        â”‚     â”‚ PostgreSQL   â”‚
â”‚                  â”‚     â”‚                  â”‚     â”‚              â”‚
â”‚  - Auth UI       â”‚â—€â”€â”€â”€â”€â”‚  - REST API      â”‚â—€â”€â”€â”€â”€â”‚  - tasks     â”‚
â”‚  - Task CRUD     â”‚     â”‚  - JWT Auth      â”‚     â”‚  - users     â”‚
â”‚  - Tailwind CSS  â”‚     â”‚  - SQLModel ORM  â”‚     â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                           â”‚
     â”‚                           â”‚
     â–¼                           â–¼
Better Auth JWT â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE III: AI-Powered Chatbot
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI ChatKit  â”‚â”€â”€â”€â”€â–¶â”‚       FastAPI Backend              â”‚
â”‚  Frontend        â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                  â”‚     â”‚  â”‚  Chat Endpoint               â”‚  â”‚
â”‚  - Chat UI       â”‚â—€â”€â”€â”€â”€â”‚  â”‚  POST /api/v1/{user}/chat   â”‚â—€â”€â”¼â”€â”€â”
â”‚  - Conversation  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  - History       â”‚     â”‚             â”‚                      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚             â–¼                      â”‚  â”‚
                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
                         â”‚  â”‚  OpenAI Agents SDK          â”‚  â”‚  â”‚
                         â”‚  â”‚  - Agent + Runner           â”‚  â”‚  â”‚
                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
                         â”‚             â”‚                      â”‚  â”‚
                         â”‚             â–¼                      â”‚  â”‚
                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
                         â”‚  â”‚  MCP Server (Official SDK)  â”‚  â”‚  â”‚
                         â”‚  â”‚  - add_task                 â”‚  â”‚  â”‚
                         â”‚  â”‚  - list_tasks               â”‚  â”‚  â”‚
                         â”‚  â”‚  - complete_task            â”‚  â”‚  â”‚
                         â”‚  â”‚  - delete_task              â”‚  â”‚  â”‚
                         â”‚  â”‚  - update_task              â”‚  â”‚  â”‚
                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                       â”‚                         â”‚
                                       â–¼                         â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
                         â”‚  Neon DB                     â”‚        â”‚
                         â”‚  - tasks                     â”‚        â”‚
                         â”‚  - users                     â”‚        â”‚
                         â”‚  - conversations  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚  - messages                  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE IV: Local Kubernetes (Minikube)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Minikube Cluster                          â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Frontend Pod â”‚  â”‚ Backend Pod  â”‚  â”‚ External DB  â”‚        â”‚
â”‚  â”‚  (Next.js)   â”‚  â”‚  (FastAPI)   â”‚  â”‚ (Neon Cloud) â”‚        â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚        â”‚
â”‚  â”‚ Deployment   â”‚  â”‚ Deployment   â”‚  â”‚ (External)   â”‚        â”‚
â”‚  â”‚ Service      â”‚  â”‚ Service      â”‚  â”‚              â”‚        â”‚
â”‚  â”‚ Ingress      â”‚  â”‚ Health Check â”‚  â”‚              â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                â”‚
â”‚  Helm Chart: todo-chart/                                      â”‚
â”‚  - Deployments, Services, Ingress                             â”‚
â”‚  - ConfigMaps, Secrets                                        â”‚
â”‚  - Resource limits                                            â”‚
â”‚                                                                â”‚
â”‚  Managed via: kubectl-ai & kagent                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE V: Cloud Production (Event-Driven)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Cloud Kubernetes (DOKS/GKE/AKS)                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Frontend  â”‚  â”‚ Backend  â”‚  â”‚         Kafka Cluster                â”‚ â”‚
â”‚  â”‚  Pod     â”‚  â”‚  Pod +   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚          â”‚  â”‚  Dapr    â”‚  â”‚  â”‚task-events â”‚  â”‚ reminders  â”‚     â”‚ â”‚
â”‚  â”‚+ Dapr    â”‚  â”‚  Sidecar â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚ Sidecar  â”‚  â”‚          â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚  â”‚task-updatesâ”‚                     â”‚ â”‚
â”‚       â”‚             â”‚        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ â”‚
â”‚       â”‚             â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚             â”‚                   â”‚                             â”‚
â”‚       â–¼             â–¼                   â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚            Dapr Components                       â”‚                â”‚
â”‚  â”‚  - Pub/Sub (Kafka)                              â”‚                â”‚
â”‚  â”‚  - State Store (PostgreSQL)                     â”‚                â”‚
â”‚  â”‚  - Jobs API (Reminders)                         â”‚                â”‚
â”‚  â”‚  - Secrets (Kubernetes Secrets)                 â”‚                â”‚
â”‚  â”‚  - Service Invocation                           â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Recurring    â”‚  â”‚ Notification â”‚  â”‚ Audit/Log    â”‚              â”‚
â”‚  â”‚ Task Service â”‚  â”‚ Service      â”‚  â”‚ Service      â”‚              â”‚
â”‚  â”‚ (Consumer)   â”‚  â”‚ (Consumer)   â”‚  â”‚ (Consumer)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                       â”‚
â”‚  CI/CD: GitHub Actions â†’ Build â†’ Push â†’ Deploy                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## PHASE I: CONSOLE APPLICATION

### Status: âœ… COMPLETE

**Timeline**: 3 days (COMPLETED on 2025-12-25)

### Implementation Sections

#### 1. Project Setup âœ…
- Initialize with UV package manager
- Create project structure (`src/phase-1/`)
- Setup Spec-Kit Plus framework
- Create initial specifications

#### 2. Data Models âœ…
- Task TypedDict with validation
- In-memory storage (Dict[int, Task])
- Auto-incrementing ID management

#### 3. Core Operations âœ…
- `add_task(title, description)` - Create new task
- `list_tasks()` - Display all tasks
- `update_task(id, title, description)` - Modify task
- `delete_task(id)` - Remove task
- `toggle_complete(id)` - Change status

#### 4. User Interface âœ…
- Menu system (1-6 options)
- Input handling with validation
- Output formatting with Unicode (âœ“, â˜)

#### 5. Validation & Error Handling âœ…
- Title: 1-200 characters
- Description: max 1000 characters
- ID existence checks
- User confirmation prompts

### Completion Checklist

- [x] All 5 basic features implemented
- [x] Console UI user-friendly
- [x] Input validation prevents crashes
- [x] Specs written before code
- [x] Code generated by Claude Code
- [x] README with setup instructions
- [x] Demo script created

---

## PHASE II: FULL-STACK WEB APPLICATION

### Status: ğŸ“‹ PLANNED

**Timeline**: 7-10 days (estimated)
**Prerequisites**: Phase I complete, Neon account created

### Research Topics

**Before Coding** (Days 1-2):
- [ ] Next.js 16 App Router architecture
- [ ] Better Auth setup and configuration
- [ ] SQLModel relationship patterns
- [ ] Neon Serverless PostgreSQL connection
- [ ] FastAPI async/await patterns
- [ ] JWT token best practices

**Reference Documentation**:
- Next.js: https://nextjs.org/docs
- FastAPI: https://fastapi.tiangolo.com
- Better Auth: https://www.better-auth.com/docs
- SQLModel: https://sqlmodel.tiangolo.com
- Neon: https://neon.tech/docs

### Implementation Sections

#### 1. Database Layer (Days 2-3)

**Tasks**:
- [ ] Design SQLModel models (User, Task)
- [ ] Setup Alembic migration framework
- [ ] Configure database connection pooling
- [ ] Create initial migration script
- [ ] Test connection to Neon database

**SQLModel Models**:
```python
# backend/src/models.py
class User(SQLModel, table=True):
    id: str = Field(primary_key=True)
    email: str = Field(unique=True, index=True)
    name: Optional[str]
    created_at: datetime

class Task(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    user_id: str = Field(foreign_key="user.id", index=True)
    title: str = Field(max_length=200)
    description: Optional[str] = Field(max_length=1000)
    completed: bool = Field(default=False, index=True)
    created_at: datetime
    updated_at: datetime
```

**Acceptance Criteria**:
- SQLModel models match database schema
- Alembic migrations apply cleanly
- Connection pooling configured (pool_size=20, max_overflow=40)
- All timestamps stored as UTC

#### 2. Backend API (Days 3-5)

**Tasks**:
- [ ] Initialize FastAPI application
- [ ] Implement authentication endpoints (register, login)
- [ ] Implement task CRUD endpoints (6 endpoints)
- [ ] Add JWT middleware
- [ ] Add error handling middleware
- [ ] Setup CORS configuration

**API Endpoints**:
```
Authentication:
POST   /api/v1/auth/register
POST   /api/v1/auth/login
POST   /api/v1/auth/logout (client-side only)

Tasks:
GET    /api/v1/{user_id}/tasks
POST   /api/v1/{user_id}/tasks
GET    /api/v1/{user_id}/tasks/{id}
PUT    /api/v1/{user_id}/tasks/{id}
DELETE /api/v1/{user_id}/tasks/{id}
PATCH  /api/v1/{user_id}/tasks/{id}/complete
```

**Acceptance Criteria**:
- All endpoints return standardized error format
- JWT authentication enforced on all endpoints (except auth)
- User can only access their own tasks (403 if not)
- Response times < 500ms
- All errors logged appropriately

#### 3. Frontend Application (Days 5-6)

**Tasks**:
- [ ] Initialize Next.js 16 with App Router
- [ ] Setup Better Auth integration
- [ ] Create API client layer (`lib/api.ts`)
- [ ] Build authentication pages (login, register)
- [ ] Build task management UI components
- [ ] Apply Tailwind CSS styling
- [ ] Add loading states and error handling

**Component Structure**:
```
frontend/src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â”œâ”€â”€ login/page.tsx
â”‚   â”‚   â””â”€â”€ register/page.tsx
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â””â”€â”€ layout.tsx
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ TaskList.tsx
â”‚   â”œâ”€â”€ TaskItem.tsx
â”‚   â”œâ”€â”€ AddTaskForm.tsx
â”‚   â”œâ”€â”€ EditTaskModal.tsx
â”‚   â””â”€â”€ DeleteConfirmModal.tsx
â””â”€â”€ lib/
    â”œâ”€â”€ api.ts
    â”œâ”€â”€ auth.ts
    â””â”€â”€ config.ts
```

**Acceptance Criteria**:
- Mobile-responsive (320px+)
- Password strength indicator shown
- Inline validation on forms
- Loading states during API calls
- Error toast notifications
- JWT stored in localStorage

#### 4. Integration & Deployment (Days 6-7)

**Tasks**:
- [ ] Configure environment variables
- [ ] Test frontend-backend communication
- [ ] Verify JWT token flow
- [ ] Setup CORS for Vercel domain
- [ ] Deploy frontend to Vercel
- [ ] Deploy backend to cloud platform
- [ ] Update database connection for production
- [ ] End-to-end testing

**Environment Configuration**:
```bash
# Backend (.env)
DATABASE_URL=postgresql://...neon.tech.../todo_prod
BETTER_AUTH_SECRET=<generated-secret>
BETTER_AUTH_URL=https://todo-app.vercel.app
ENVIRONMENT=production
LOG_LEVEL=INFO

# Frontend (.env.local)
NEXT_PUBLIC_API_URL=https://api-todo-app.fly.dev
```

**Acceptance Criteria**:
- Frontend accessible at Vercel URL
- Backend accessible and responding
- Users can register and login
- Tasks persist across sessions
- No CORS errors
- SSL/TLS working

### Testing Strategy

**Unit Tests** (pytest for backend):
```python
def test_create_task_success():
    response = client.post("/api/v1/user123/tasks",
        json={"title": "Test", "description": "Test"},
        headers={"Authorization": f"Bearer {valid_token}"})
    assert response.status_code == 201
    assert response.json()["title"] == "Test"

def test_create_task_unauthorized():
    response = client.post("/api/v1/user123/tasks",
        json={"title": "Test"})
    assert response.status_code == 401
    assert response.json()["error"]["code"] == "AUTH_UNAUTHORIZED"
```

**Integration Tests**:
- [ ] User registration â†’ login â†’ create task â†’ logout â†’ login â†’ view task
- [ ] Invalid token â†’ 401 error
- [ ] Wrong user_id â†’ 403 error
- [ ] Database restart â†’ data persists

### Completion Checklist

- [ ] Users can register and login
- [ ] JWT authentication working
- [ ] All REST API endpoints functional
- [ ] Frontend deployed to Vercel
- [ ] Backend deployed and accessible
- [ ] Database persists data
- [ ] User isolation enforced
- [ ] Mobile responsive
- [ ] Alembic migrations setup
- [ ] Environment variables externalized
- [ ] Specs updated
- [ ] Demo video < 90 seconds

---

## PHASE III: AI CHATBOT

### Status: ğŸ“‹ PLANNED

**Timeline**: 7-10 days (estimated)
**Prerequisites**: Phase II complete, OpenAI API key obtained

### Research Topics

**Before Coding** (Days 1-2):
- [ ] OpenAI Agents SDK architecture
- [ ] Official MCP SDK (Python) usage
- [ ] MCP tool schema definition
- [ ] OpenAI ChatKit setup guide
- [ ] Stateless conversation management patterns

**Reference Documentation**:
- OpenAI Agents SDK: https://platform.openai.com/docs/agents
- MCP SDK: https://github.com/modelcontextprotocol/python-sdk
- ChatKit: https://platform.openai.com/docs/guides/chatkit

### Implementation Sections

#### 1. MCP Server (Days 2-3)

**Tasks**:
- [ ] Install Official MCP SDK (Python)
- [ ] Define 5 MCP tool schemas
- [ ] Implement tool database integration
- [ ] Add standardized error handling
- [ ] Format tool responses per spec

**MCP Tool Implementations**:
```python
# backend/src/mcp/tools.py

@mcp_tool_wrapper("add_task")
async def add_task(user_id: str, title: str, description: str = "") -> Dict:
    """Add a new task to the user's task list"""
    try:
        task = await db.create_task(user_id, title, description)
        return {
            "task_id": task.id,
            "title": task.title,
            "completed": task.completed,
            "created_at": task.created_at.isoformat()
        }
    except ValidationError as e:
        raise  # Wrapper handles

@mcp_tool_wrapper("list_tasks")
async def list_tasks(user_id: str, status: str = "all") -> List[Dict]:
    """List all tasks for the user"""
    ...

@mcp_tool_wrapper("complete_task")
async def complete_task(user_id: str, task_id: int) -> Dict:
    """Mark a task as complete or incomplete"""
    ...

@mcp_tool_wrapper("delete_task")
async def delete_task(user_id: str, task_id: int) -> Dict:
    """Delete a task"""
    ...

@mcp_tool_wrapper("update_task")
async def update_task(user_id: str, task_id: int,
                      title: Optional[str] = None,
                      description: Optional[str] = None) -> Dict:
    """Update task details"""
    ...
```

**Acceptance Criteria**:
- All tools accept user_id as first parameter
- Tools return `{success, data/error, metadata}` format
- Error codes match specs/technical/error-codes.md
- Tools are stateless (no in-memory caching)

#### 2. Conversation Persistence (Days 3-4)

**Tasks**:
- [ ] Create Alembic migration for conversations/messages tables
- [ ] Implement conversation CRUD operations
- [ ] Implement message CRUD operations
- [ ] Add conversation history loading
- [ ] Test conversation retrieval

**Database Schema**:
```sql
CREATE TABLE conversations (
  id SERIAL PRIMARY KEY,
  user_id VARCHAR(255) REFERENCES users(id),
  created_at TIMESTAMP DEFAULT (NOW() AT TIME ZONE 'UTC'),
  updated_at TIMESTAMP DEFAULT (NOW() AT TIME ZONE 'UTC')
);

CREATE TABLE messages (
  id SERIAL PRIMARY KEY,
  conversation_id INTEGER REFERENCES conversations(id) ON DELETE CASCADE,
  user_id VARCHAR(255) REFERENCES users(id),
  role VARCHAR(20) NOT NULL,  -- 'user' or 'assistant'
  content TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT (NOW() AT TIME ZONE 'UTC')
);

CREATE INDEX idx_messages_conversation ON messages(conversation_id);
CREATE INDEX idx_conversations_user ON conversations(user_id);
```

**Acceptance Criteria**:
- Conversations stored per user
- Messages linked to conversations
- Cascade delete working
- History loads in chronological order

#### 3. AI Agent Integration (Days 4-5)

**Tasks**:
- [ ] Install OpenAI Agents SDK
- [ ] Configure agent with system prompt
- [ ] Register MCP tools with agent
- [ ] Implement conversation context management
- [ ] Test agent intent recognition

**Agent Configuration**:
```python
# backend/src/ai/agent.py
from openai import Agent

SYSTEM_PROMPT = """
You are a helpful task management assistant.

When users mention tasks, you can:
- Add tasks with natural language
- List their tasks
- Mark tasks as complete
- Delete tasks
- Update task details

Always:
- Interpret times in the user's timezone
- Confirm actions with friendly messages
- Handle errors gracefully
- Use checkboxes âœ“ and â˜ in responses

Error handling:
- TASK_NOT_FOUND: "I couldn't find that task. It may have been deleted."
- TASK_UNAUTHORIZED: "That task doesn't belong to you."
- VALIDATION_ERROR: Explain what needs to be fixed
"""

agent = Agent(
    model="gpt-4-turbo",
    system_prompt=SYSTEM_PROMPT,
    tools=[add_task, list_tasks, complete_task, delete_task, update_task]
)
```

**Acceptance Criteria**:
- Agent correctly identifies user intent
- Agent calls appropriate MCP tools
- Agent handles tool errors gracefully
- Agent provides friendly confirmations

#### 4. Stateless Chat Endpoint (Days 5-6)

**Tasks**:
- [ ] Create POST /api/v1/{user_id}/chat endpoint
- [ ] Implement conversation history loading
- [ ] Integrate agent execution
- [ ] Save messages to database
- [ ] Return response immediately

**Chat Endpoint Flow**:
```python
@router.post("/{user_id}/chat")
async def chat(
    user_id: str,
    message: str,
    conversation_id: Optional[int] = None,
    current_user: User = Depends(get_current_user)
):
    # 1. Load or create conversation
    if conversation_id:
        conv = await db.get_conversation(conversation_id, user_id)
        history = await db.get_messages(conversation_id)
    else:
        conv = await db.create_conversation(user_id)
        history = []

    # 2. Save user message
    await db.save_message(conv.id, user_id, "user", message)

    # 3. Build context for agent
    messages = [...history, {"role": "user", "content": message}]

    # 4. Run agent
    response = await agent.run(messages, user_id=user_id)

    # 5. Save assistant response
    await db.save_message(conv.id, user_id, "assistant", response.content)

    # 6. Return response
    return {
        "conversation_id": conv.id,
        "response": response.content,
        "tool_calls": response.tool_calls
    }
```

**Acceptance Criteria**:
- Endpoint is stateless
- History loaded from database
- Agent runs with full context
- Messages saved successfully
- Server can restart without losing data

#### 5. Frontend Chat UI (Days 6-7)

**Tasks**:
- [ ] Install OpenAI ChatKit library
- [ ] Configure ChatKit component
- [ ] Add domain to allowlist
- [ ] Integrate with chat endpoint
- [ ] Display conversation history

**ChatKit Integration**:
```typescript
// frontend/src/app/chat/page.tsx
import { ChatKit } from '@openai/chatkit'

export default function ChatPage() {
  const [conversationId, setConversationId] = useState<number | null>(null)

  async function sendMessage(message: string) {
    const response = await fetch(`${API_URL}/api/v1/${userId}/chat`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        message,
        conversation_id: conversationId
      })
    })

    const data = await response.json()
    setConversationId(data.conversation_id)
    return data.response
  }

  return (
    <ChatKit
      onSendMessage={sendMessage}
      placeholder="Ask me to manage your tasks..."
    />
  )
}
```

**Acceptance Criteria**:
- ChatKit renders correctly
- Messages send to backend
- Responses display in chat
- Conversation persists across page refreshes
- Domain allowlist configured

### Testing Strategy

**MCP Tool Tests**:
```python
def test_add_task_mcp():
    response = await add_task("user123", "Test Task", "Description")
    assert response["success"] == True
    assert response["data"]["title"] == "Test Task"
    assert "metadata" in response

def test_task_not_found_error():
    response = await complete_task("user123", 999)
    assert response["success"] == False
    assert response["error"]["code"] == "TASK_NOT_FOUND"
```

**Agent Intent Tests**:
- [ ] "Add a task to buy groceries" â†’ calls add_task
- [ ] "What's on my list?" â†’ calls list_tasks
- [ ] "Mark task 1 as done" â†’ calls complete_task
- [ ] "Delete the groceries task" â†’ calls delete_task
- [ ] "Change task 1 to 'Buy milk'" â†’ calls update_task

**Conversation Persistence Tests**:
- [ ] Create conversation â†’ send message â†’ restart server â†’ continue conversation
- [ ] Multiple conversations per user
- [ ] Conversation history loads correctly

### Completion Checklist

- [ ] ChatKit UI integrated
- [ ] All 5 MCP tools working
- [ ] AI agent interprets commands correctly
- [ ] Conversations persist in database
- [ ] Server is stateless
- [ ] Error handling graceful
- [ ] Natural language commands work
- [ ] Domain allowlist configured
- [ ] Specs updated
- [ ] Demo video < 90 seconds

---

## PHASE IV: LOCAL KUBERNETES DEPLOYMENT

### Status: ğŸ“‹ PLANNED

**Timeline**: 7-10 days (estimated)
**Prerequisites**: Phase III complete, Docker Desktop installed, Minikube installed

### Research Topics

**Before Coding** (Days 1-2):
- [ ] Docker multi-stage builds
- [ ] Kubernetes fundamentals (Pods, Deployments, Services)
- [ ] Helm chart structure
- [ ] Minikube installation and setup
- [ ] kubectl-ai and kagent capabilities

**Reference Documentation**:
- Docker: https://docs.docker.com/build/building/multi-stage/
- Kubernetes: https://kubernetes.io/docs
- Helm: https://helm.sh/docs
- Minikube: https://minikube.sigs.k8s.io/docs/

### Implementation Sections

#### 1. Containerization (Days 2-3)

**Frontend Dockerfile**:
```dockerfile
# Multi-stage build
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:20-alpine AS runner
WORKDIR /app
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001
COPY --from=builder --chown=nextjs:nodejs /app/.next ./.next
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./package.json

USER nextjs
EXPOSE 3000
ENV PORT 3000

HEALTHCHECK --interval=30s --timeout=3s \
  CMD node -e "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

CMD ["npm", "start"]
```

**Backend Dockerfile**:
```dockerfile
# Multi-stage build
FROM python:3.13-slim AS builder
WORKDIR /app
RUN pip install uv
COPY pyproject.toml uv.lock ./
RUN uv sync

FROM python:3.13-slim AS runner
WORKDIR /app
RUN adduser --disabled-password --uid 1001 apiuser
COPY --from=builder /app/.venv ./.venv
COPY . .

USER apiuser
EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=3s \
  CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"

CMD [".venv/bin/uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Acceptance Criteria**:
- Images build successfully
- Images run as non-root user
- Health check endpoints implemented
- Images < 200MB (frontend), < 150MB (backend)
- Multi-stage builds optimize size

#### 2. Helm Charts (Days 3-5)

**Chart Structure**:
```
infrastructure/helm/todo-chart/
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ values.yaml
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ _helpers.tpl
â”‚   â”œâ”€â”€ frontend-deployment.yaml
â”‚   â”œâ”€â”€ frontend-service.yaml
â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â”œâ”€â”€ backend-service.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ secrets.yaml
â”‚   â””â”€â”€ ingress.yaml
```

**values.yaml**:
```yaml
frontend:
  image:
    repository: ghcr.io/user/todo-frontend
    tag: v1.0.0
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

backend:
  image:
    repository: ghcr.io/user/todo-backend
    tag: v1.0.0
  replicas: 1
  resources:
    requests:
      cpu: 200m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi

database:
  url: postgresql://user:pass@neon.tech/todo_staging

ingress:
  enabled: true
  host: todo.local
```

**Acceptance Criteria**:
- Helm chart installs successfully
- All resources created correctly
- ConfigMaps and Secrets working
- Resource limits defined
- Chart customizable via values.yaml

#### 3. Minikube Setup (Days 5-6)

**Tasks**:
- [ ] Install Minikube
- [ ] Start cluster with appropriate resources
- [ ] Enable ingress addon
- [ ] Configure local docker registry (optional)
- [ ] Test cluster connectivity

**Setup Commands**:
```bash
# Start Minikube with 8GB RAM, 4 CPUs
minikube start --memory=8192 --cpus=4

# Enable ingress
minikube addons enable ingress

# Get cluster IP
minikube ip  # e.g., 192.168.49.2
```

**Acceptance Criteria**:
- Minikube cluster running
- Kubectl can connect
- Ingress addon enabled
- Minimum 4GB RAM, 2 CPUs allocated

#### 4. Deployment & Operations (Days 6-7)

**Tasks**:
- [ ] Build Docker images
- [ ] Push images to registry
- [ ] Install Helm chart
- [ ] Verify all pods running
- [ ] Test frontend accessibility
- [ ] Test backend health check
- [ ] Install kubectl-ai
- [ ] Practice AI-assisted operations

**Deployment Script**:
```bash
#!/bin/bash
# deploy.sh

# Build images
docker build -t ghcr.io/user/todo-frontend:v1.0.0 frontend/
docker build -t ghcr.io/user/todo-backend:v1.0.0 backend/

# Push to registry
docker push ghcr.io/user/todo-frontend:v1.0.0
docker push ghcr.io/user/todo-backend:v1.0.0

# Install with Helm
helm install todo-app ./infrastructure/helm/todo-chart \
  --set backend.image.tag=v1.0.0 \
  --set frontend.image.tag=v1.0.0 \
  --set database.url=$DATABASE_URL

# Verify deployment
kubectl get pods
kubectl get services
kubectl get ingress

# Check health
kubectl exec -it backend-xxx -- curl http://localhost:8000/health
```

**kubectl-ai Examples**:
```bash
# Diagnose pod failures
kubectl-ai "why is the backend pod failing?"

# Check connectivity
kubectl-ai "can the frontend reach the backend?"

# Scale services
kubectl-ai "scale the backend to 3 replicas"

# Analyze logs
kubectl-ai "show me errors in backend logs"
```

**Acceptance Criteria**:
- All pods show "Running" status
- Health checks passing
- Frontend accessible via ingress
- Backend reachable from frontend
- kubectl-ai can diagnose issues
- Documentation allows fresh deployment < 30 min

### Testing Strategy

**Deployment Tests**:
- [ ] `helm install` succeeds
- [ ] All pods reach Running state
- [ ] Services created correctly
- [ ] Ingress routing works
- [ ] ConfigMaps/Secrets mounted correctly

**Health Check Tests**:
- [ ] Liveness probes pass
- [ ] Readiness probes pass
- [ ] /health endpoints return 200

**kubectl-ai Tests**:
- [ ] Can query cluster state
- [ ] Can diagnose failures
- [ ] Can suggest fixes
- [ ] Commands execute correctly

### Completion Checklist

- [ ] Both services containerized
- [ ] Health checks implemented
- [ ] Helm chart deploys successfully
- [ ] Services running in Minikube
- [ ] Frontend accessible
- [ ] Backend accessible from frontend
- [ ] kubectl-ai configured
- [ ] Documentation complete
- [ ] Resource limits configured
- [ ] Specs updated
- [ ] Demo video < 90 seconds

---

## PHASE V: CLOUD PRODUCTION DEPLOYMENT

### Status: ğŸ“‹ PLANNED

**Timeline**: 14-21 days (estimated)
**Prerequisites**: Phase IV complete, Cloud account created, Kafka service selected

### Research Topics

**Before Coding** (Days 1-3):
- [ ] Kafka fundamentals and topic design
- [ ] Dapr architecture and components
- [ ] Event-driven microservices patterns
- [ ] DigitalOcean DOKS / GKE / AKS setup
- [ ] GitHub Actions Kubernetes deployment
- [ ] Natural language date parsing (dateparser)
- [ ] Horizontal Pod Autoscaler configuration

**Reference Documentation**:
- Kafka: https://kafka.apache.org/documentation/
- Dapr: https://docs.dapr.io
- Redpanda: https://docs.redpanda.com
- Cloud providers: DOKS/GKE/AKS docs
- GitHub Actions: https://docs.github.com/actions

### Implementation Sections

#### 1. Advanced Task Features (Days 3-6)

**Database Migration**:
```sql
-- Migration: 003_add_advanced_features

ALTER TABLE tasks ADD COLUMN priority VARCHAR(20) DEFAULT 'medium';
ALTER TABLE tasks ADD COLUMN due_date TIMESTAMP;
ALTER TABLE tasks ADD COLUMN remind_at TIMESTAMP;
ALTER TABLE tasks ADD COLUMN recurrence_pattern VARCHAR(100);
ALTER TABLE tasks ADD COLUMN is_recurring BOOLEAN DEFAULT FALSE;

CREATE TABLE tags (
  id SERIAL PRIMARY KEY,
  name VARCHAR(50) UNIQUE NOT NULL,
  created_at TIMESTAMP DEFAULT (NOW() AT TIME ZONE 'UTC')
);

CREATE TABLE task_tags (
  task_id INTEGER REFERENCES tasks(id) ON DELETE CASCADE,
  tag_id INTEGER REFERENCES tags(id) ON DELETE CASCADE,
  PRIMARY KEY (task_id, tag_id)
);

CREATE INDEX idx_tasks_priority ON tasks(priority);
CREATE INDEX idx_tasks_due_date ON tasks(due_date);
CREATE INDEX idx_tasks_remind_at ON tasks(remind_at);
CREATE INDEX idx_tasks_is_recurring ON tasks(is_recurring);
```

**API Updates**:
```
GET    /api/v1/{user_id}/tasks?priority=high
GET    /api/v1/{user_id}/tasks?tags=work,urgent
GET    /api/v1/{user_id}/tasks?due_after=2024-12-25
GET    /api/v1/{user_id}/tasks?search=groceries
POST   /api/v1/{user_id}/tasks/{id}/tags
DELETE /api/v1/{user_id}/tasks/{id}/tags/{tag_id}
```

**Acceptance Criteria**:
- Priority field (high/medium/low) working
- Tags can be assigned and filtered
- Due dates accepted and stored
- Reminders scheduled via Dapr Jobs
- Search by keyword working
- Filters combinable (AND logic)

#### 2. Event-Driven Architecture (Days 6-9)

**Kafka Topics**:
```yaml
task-events:
  partitions: 3
  replication_factor: 3
  retention_ms: 604800000  # 7 days
  schema:
    event_type: created|updated|completed|deleted
    task_id: integer
    user_id: string
    task_data: object
    timestamp: datetime (UTC)

reminders:
  partitions: 3
  replication_factor: 3
  retention_ms: 86400000  # 1 day
  schema:
    task_id: integer
    user_id: string
    title: string
    due_at: datetime
    remind_at: datetime

task-updates:
  partitions: 3
  replication_factor: 3
  retention_ms: 3600000  # 1 hour
  schema:
    operation: add|update|delete|complete
    task_id: integer
    user_id: string
    task_data: object
```

**Event Producer** (FastAPI):
```python
# backend/src/events/producer.py
from dapr.clients import DaprClient

async def publish_task_event(event_type: str, task: Task):
    event = {
        "event_type": event_type,
        "task_id": task.id,
        "user_id": task.user_id,
        "task_data": task.dict(),
        "timestamp": datetime.now(timezone.utc).isoformat()
    }

    async with DaprClient() as client:
        await client.publish_event(
            pubsub_name="kafka-pubsub",
            topic_name="task-events",
            data=json.dumps(event)
        )
```

**Event Consumers** (3 Services):

1. **Recurring Task Service**:
```python
# services/recurring-tasks/main.py
@app.subscribe(pubsub_name="kafka-pubsub", topic="task-events")
async def handle_task_completed(event: dict):
    if event["event_type"] == "completed":
        task_data = event["task_data"]
        if task_data.get("is_recurring"):
            # Calculate next occurrence
            next_due = calculate_next_occurrence(task_data)
            # Create new task
            await create_next_instance(task_data, next_due)
```

2. **Notification Service**:
```python
# services/notifications/main.py
@app.subscribe(pubsub_name="kafka-pubsub", topic="reminders")
async def handle_reminder(event: dict):
    # Send browser notification
    await send_push_notification(
        user_id=event["user_id"],
        title=f"Reminder: {event['title']}",
        body=f"Due: {event['due_at']}"
    )
```

3. **Audit Service**:
```python
# services/audit/main.py
@app.subscribe(pubsub_name="kafka-pubsub", topic="task-events")
async def log_task_event(event: dict):
    # Log all task events for audit trail
    await db.save_audit_log(event)
```

**Acceptance Criteria**:
- All CRUD operations publish events
- Events have correct schema
- Consumers are idempotent
- Dead letter queue configured
- Event retention set to 7 days

#### 3. Dapr Integration (Days 9-11)

**Dapr Components**:

**Pub/Sub (Kafka)**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: kafka-pubsub
spec:
  type: pubsub.kafka
  version: v1
  metadata:
    - name: brokers
      value: "kafka-broker1:9092,kafka-broker2:9092"
    - name: consumerGroup
      value: "todo-service"
    - name: authType
      value: "none"  # or "sasl" for Redpanda Cloud
```

**State Store (PostgreSQL)**:
```yaml
apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: statestore
spec:
  type: state.postgresql
  version: v1
  metadata:
    - name: connectionString
      value: "host=neon.tech user=... dbname=todo password=..."
```

**Jobs (Reminders)**:
```python
# Schedule reminder
await httpx.post(
    "http://localhost:3500/v1.0-alpha1/jobs/reminder-task-123",
    json={
        "dueTime": "2024-12-25T09:00:00Z",
        "data": {
            "task_id": 123,
            "user_id": "user_abc",
            "type": "reminder"
        }
    }
)

# Callback endpoint
@app.post("/api/jobs/trigger")
async def handle_job_trigger(request: Request):
    job_data = await request.json()
    if job_data["data"]["type"] == "reminder":
        await publish_event("reminders", job_data["data"])
    return {"status": "SUCCESS"}
```

**Acceptance Criteria**:
- All Kafka interactions via Dapr Pub/Sub
- State store working for conversation context
- Reminders scheduled via Jobs API
- Secrets retrieved via Dapr Secrets API
- Service invocation between microservices

#### 4. Cloud Deployment (Days 11-13)

**Tasks**:
- [ ] Create cloud Kubernetes cluster (DOKS/GKE/AKS)
- [ ] Install Dapr on cluster
- [ ] Setup Kafka (Redpanda Cloud or Strimzi)
- [ ] Deploy Helm chart to cloud
- [ ] Configure DNS and SSL
- [ ] Setup monitoring (basic)
- [ ] Configure HPA (Horizontal Pod Autoscaler)

**HPA Configuration**:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
    scaleUp:
      stabilizationWindowSeconds: 60
```

**Acceptance Criteria**:
- Cluster running in cloud
- All services deployed
- Dapr sidecars injected
- Kafka accessible
- SSL/TLS working
- Auto-scaling configured
- Health checks passing

#### 5. CI/CD Pipeline (Days 13-14)

**GitHub Actions Workflow**:
```yaml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Build Docker Images
        run: |
          docker build -t ghcr.io/${{ github.repository }}/frontend:${{ github.sha }} frontend/
          docker build -t ghcr.io/${{ github.repository }}/backend:${{ github.sha }} backend/

      - name: Push to Registry
        run: |
          echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin
          docker push ghcr.io/${{ github.repository }}/frontend:${{ github.sha }}
          docker push ghcr.io/${{ github.repository }}/backend:${{ github.sha }}

      - name: Deploy with Helm
        run: |
          helm upgrade --install todo-app ./infrastructure/helm/todo-chart \
            --set frontend.image.tag=${{ github.sha }} \
            --set backend.image.tag=${{ github.sha }} \
            --set database.url=${{ secrets.DATABASE_URL }}

      - name: Verify Deployment
        run: |
          kubectl rollout status deployment/frontend
          kubectl rollout status deployment/backend
          kubectl get pods
```

**Acceptance Criteria**:
- Push to main triggers build
- Docker images built and pushed
- Helm deploys to cluster
- Health checks verified
- Rollback works on failure

### Testing Strategy

**Event Flow Tests**:
- [ ] Create task â†’ event published â†’ consumers receive
- [ ] Complete recurring task â†’ new task created
- [ ] Reminder time reached â†’ notification sent
- [ ] Event replay works correctly

**Load Tests**:
```bash
# Use k6 for load testing
k6 run --vus 100 --duration 30s load-test.js
```

**Integration Tests**:
- [ ] End-to-end user flow with all features
- [ ] Search returns correct results
- [ ] Filters work with multiple criteria
- [ ] Recurring tasks generate on schedule
- [ ] Reminders trigger at correct time

### Completion Checklist

- [ ] All advanced features implemented
- [ ] Kafka topics created
- [ ] All events publishing
- [ ] All 3 consumer services working
- [ ] Dapr components configured
- [ ] Reminders trigger correctly
- [ ] Recurring tasks auto-generate
- [ ] Search and filter working
- [ ] Deployed to cloud Kubernetes
- [ ] CI/CD pipeline operational
- [ ] Auto-scaling configured
- [ ] Monitoring setup
- [ ] Load tested (100+ users)
- [ ] Specs updated
- [ ] Demo video < 90 seconds

---

## CROSS-PHASE CONSIDERATIONS

### Architectural Decisions Needing Documentation

#### Decision 1: In-Memory Data Structure (Phase I) âœ…
**Decision**: Dictionary with ID as key (`Dict[int, Task]`)
**Rationale**: O(1) lookup by ID, easy iteration, sets foundation for database transition
**Documentation**: `specs/phase-1/spec.md`

#### Decision 2: Frontend Framework (Phase II)
**Decision**: Next.js 16+ App Router (REQUIRED)
**Rationale**: CONSTITUTION requirement, modern pattern, better performance
**Documentation**: `CONSTITUTION.md Section II`

#### Decision 3: Database (Phase II+)
**Decision**: Neon Serverless PostgreSQL (REQUIRED)
**Rationale**: SPECIFICATION requirement, cloud-native, generous free tier
**Documentation**: `SPECIFICATION.md Phase II`

#### Decision 4: MCP Implementation (Phase III)
**Decision**: Official MCP SDK (Python) (REQUIRED)
**Rationale**: SPECIFICATION requirement, standardized protocol
**Documentation**: `SPECIFICATION.md Phase III`

#### Decision 5: Kafka Deployment (Phase V)
**Decision**: Redpanda Cloud with Strimzi fallback
**Rationale**: Free tier available, simple setup, Kafka-compatible
**Documentation**: `specs/infrastructure/kafka.md` (to be created)

#### Decision 6: AI Model Selection (Phase III+)
**Decision**: GPT-4-turbo
**Rationale**: Best balance of cost, speed, and capability
**Documentation**: `specs/technical/environment-config.md`

#### Decision 7: Container Registry (Phase IV+)
**Decision**: GitHub Container Registry (ghcr.io)
**Rationale**: Free, integrated with GitHub, good for CI/CD
**Documentation**: `CONSTITUTION.md Section XIII`

---

## IMPLEMENTATION WORKFLOW (Spec-Driven)

For **every feature** in **every phase**:

```
1. SPECIFY
   â””â”€ Write/update spec in /specs/features/ or /specs/phase-X/
   â””â”€ Define acceptance criteria
   â””â”€ Reference CONSTITUTION principles

2. PLAN (this document)
   â””â”€ Break down into implementation sections
   â””â”€ Identify research needs
   â””â”€ Define testing approach

3. TASK BREAKDOWN
   â””â”€ Create granular tasks in /specs/tasks/
   â””â”€ Each task maps to spec section
   â””â”€ Estimate complexity

4. IMPLEMENT (with Claude Code)
   â””â”€ Refine spec until Claude generates correct code
   â””â”€ Document all prompt iterations in PHR
   â””â”€ Never write code manually
   â””â”€ Test each task completion

5. VALIDATE
   â””â”€ Run acceptance tests
   â””â”€ Compare output to spec criteria
   â””â”€ Update spec if requirements change

6. DOCUMENT
   â””â”€ Update CLAUDE.md with learnings
   â””â”€ Add to /specs/technical/ if needed
   â””â”€ Create PHR for session
   â””â”€ Record decisions made
```

---

## SUCCESS METRICS

### Phase Completion Indicators

| Phase | Primary Metric | Secondary Metrics |
|-------|----------------|-------------------|
| I | All 5 features working | Specs complete, Code generated by AI |
| II | Users can CRUD tasks via web | JWT working, Database persisting, Mobile responsive |
| III | Natural language commands work | MCP tools functional, Conversations persist |
| IV | Services running in Minikube | Helm deploys, Health checks passing, kubectl-ai working |
| V | Production deployment live | Events flowing, Reminders triggering, Auto-scaling working |

### Quality Gates

**Before Proceeding to Next Phase**:
- [ ] All acceptance criteria met (100%)
- [ ] Demo video created (< 90 seconds)
- [ ] Specifications updated
- [ ] PHR created for all sessions
- [ ] Constitution compliance verified
- [ ] No manual code written

---

## TIMELINE ESTIMATES

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| Phase I | 3 days | UV installed, Python 3.13+ |
| Phase II | 7-10 days | Neon account, Better Auth setup |
| Phase III | 7-10 days | OpenAI API key |
| Phase IV | 7-10 days | Docker, Minikube, kubectl-ai |
| Phase V | 14-21 days | Cloud account, Kafka service |

**Total Estimated Duration**: 38-54 days (~6-8 weeks)

**Note**: Timelines assume full-time development (8 hours/day). Adjust for part-time work accordingly.

---

## REFERENCES

- [SPECIFICATION.md](../../../SPECIFICATION.md) - Feature requirements
- [CONSTITUTION.md](../.specify/memory/constitution.md) - Project principles
- [AGENTS.md](../AGENTS.md) - Agent behavior guide
- [specs/technical/error-codes.md](technical/error-codes.md) - Error handling
- [specs/technical/database-migrations.md](technical/database-migrations.md) - Database evolution
- [specs/technical/environment-config.md](technical/environment-config.md) - Configuration management
- [specs/technical/timezone-handling.md](technical/timezone-handling.md) - Timezone strategy

---

**This technical plan serves as the authoritative roadmap for implementing all 5 phases of the Evolution of Todo project. All implementation must follow the Spec-Driven Development workflow outlined herein.**

---

**Version**: 1.0.0
**Created**: 2025-12-25
**Status**: Phase I Complete, Phase II-V Planned
